{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro and Markets Dashboard\n",
    "## Executive Version -- United States\n",
    "\n",
    "Brian W. Dew (brianwdew@gmail.com), as of January 15, 2017\n",
    "\n",
    "---\n",
    "\n",
    "#### Objective:\n",
    "Using python, obtain economic data from the web and save it as csv and txt files to be read by a LaTex file containing chart formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:18.763671Z",
     "start_time": "2018-06-08T01:27:18.232423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import quandl\n",
    "import config   ## File with API key\n",
    "quandl.ApiConfig.api_key = config.key\n",
    "\n",
    "os.chdir('C:\\Working\\Python\\Macro_Dash\\data')\n",
    "\n",
    "def write_txt(filename, filetext):\n",
    "# Write label to txt file\n",
    "    with open(filename, 'w') as text_file:\n",
    "        text_file.write(filetext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real GDP \n",
    "\n",
    "Currently retrieved from FRED. More ideal would be to use the BEA API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:19.482555Z",
     "start_time": "2018-06-08T01:27:18.763671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inputs to pandas datareader:\n",
    "start = datetime.datetime(2005,1,1)\n",
    "series = ['GCEC1', 'GPDIC1', 'NETEXC', 'PCECC96', 'GDPC1']\n",
    "\n",
    "# Retrieve data as pandas dataframe named df\n",
    "df = web.DataReader(series, 'fred', start)\n",
    "\n",
    "# Record strings for later use in chart label\n",
    "date = '{} Q{}'.format(df.index[-1].year, df.index[-1].quarter)\n",
    "Y = (df['GDPC1'][-1] / 1000).round(1)  # GDP in levels\n",
    "\n",
    "for s in series:  # Convert to share of total change\n",
    "    df[s] = ((1 + (df[s] - df[s].shift(1))\n",
    "              /df['GDPC1'].shift(1))**4 - 1) * 100\n",
    "    \n",
    "df[4:].round(1).to_csv('gdp_comp.csv') # Save to csv\n",
    "\n",
    "# Declare variables for chart label\n",
    "ch = df['GDPC1'][-1].round(1)  # GDP in growth\n",
    "label = '{}: Real GDP: {}T; Growth: {}\\%'.format(date, Y, ch)\n",
    "\n",
    "write_txt('gdp_comp.txt', label) # Write chart label to txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment Rates\n",
    "\n",
    "Collect U3 data from FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:19.810679Z",
     "start_time": "2018-06-08T01:27:19.482555Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime(2006,1,1) \n",
    "series = ['UNRATE', 'LNS14027659', 'LNS14027662']\n",
    "\n",
    "# Retrieve data as pandas dataframe named df\n",
    "df = web.DataReader(series, 'fred', start)\n",
    "df.to_csv('unemp.csv')  # save to csv\n",
    "\n",
    "last = df['UNRATE'][-1] # Current U3 rate\n",
    "date = df.index[-1].strftime('%b %Y')\n",
    "label = '{}: {}\\%'.format(date, last)\n",
    "write_txt('unemp.txt', label) # label to txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Price Index (CPI) time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:20.888803Z",
     "start_time": "2018-06-08T01:27:19.810679Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inputs to the pandas datareader:\n",
    "start = datetime.datetime(2005,1,1) \n",
    "series = ['CPIAUCSL', 'CPILFESL', 'T5YIFR']             \n",
    "df = web.DataReader(series, 'fred', start)\n",
    "\n",
    "# Inflation breakeven data as extra chart label\n",
    "exp_inf = round(df['T5YIFR'].dropna()[-1],1)\n",
    "exp_dt = df['T5YIFR'].dropna().index[-1].strftime('%b %d, %Y')\n",
    "label = '{}: {}\\%'.format(exp_dt, exp_inf)\n",
    "write_txt('breakeven.txt', label) # label to txt file\n",
    "\n",
    "df = df[series[:2]].dropna().pct_change(12) * 100\n",
    "df[12:].round(1).to_csv('cpi.csv') # Save to csv\n",
    "\n",
    "# CPI time series chart main label to txt\n",
    "label = '{}: All-items CPI: {}\\%; Core CPI: {}\\%'.format(\n",
    "    df.index[-1].strftime('%b %Y'),\n",
    "    df['CPIAUCSL'].iloc[-1].round(1), \n",
    "    df['CPILFESL'].iloc[-1].round(1))\n",
    "write_txt('cpi.txt', label) # label to txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI recent changes by component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:22.857657Z",
     "start_time": "2018-06-08T01:27:20.888803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Updated inputs to pandas datareader:\n",
    "start = datetime.datetime(2006,1,1)\n",
    "series = {'CPIOGSSL': 'Other goods \\& services',\n",
    "          'CPIEDUSL': 'Educ. \\& communication',\n",
    "          'CPIRECSL': 'Recreation', \n",
    "          'CPIFABSL': 'Food \\& beverage', \n",
    "          'CPITRNSL': 'Transportation',\n",
    "          'CPIHOSSL': 'Housing', \n",
    "          'CPIENGSL': 'Energy', \n",
    "          'CPIMEDSL': 'Healthcare', \n",
    "          'CPIAPPSL': 'Apparel'}\n",
    "\n",
    "# Retrieve data as pandas dataframe named df\n",
    "df = web.DataReader(series.keys(), 'fred', start)\n",
    "df.columns = series.values()\n",
    "\n",
    "# Obtain the annual percent change (inflation rate)\n",
    "df = df.pct_change(12) * 100\n",
    "d = {s: df[s][-120:].mean() for s in df.keys()} # 10-yr avg\n",
    "\n",
    "# Write legend months to txt file\n",
    "write_txt('cpi_mo1.txt', df.index[-2].strftime('%b %Y'))\n",
    "write_txt('cpi_mo2.txt', df.index[-1].strftime('%b %Y'))\n",
    "\n",
    "# Keep only latest two months, transpose, and round\n",
    "df = df.tail(2).transpose().round(1)\n",
    "df.columns = ['one', 'two']\n",
    "df.loc[:]['ten'] = [round(d[x],1) for x in df.index]\n",
    "df.index.name = 'Item'\n",
    "df = df.sort_values(by='two', axis=0, ascending=False)\n",
    "df.to_csv('cpi_comp.csv')  # save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPS by sector from S&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:25.029653Z",
     "start_time": "2018-06-08T01:27:22.857657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BDew\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py:329: FutureWarning: The `sheetname` keyword is deprecated, use `sheet_name` instead\n",
      "  **kwds)\n",
      "C:\\Users\\BDew\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n",
      "C:\\Users\\BDew\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\Users\\BDew\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Get xlsx data from Standard and Poor's website\n",
    "spfile = 'https://us.spindices.com/documents/additional-material/sp-500-eps-est.xlsx'\n",
    "    \n",
    "df = pd.read_excel(spfile, sheetname='SECTOR EPS', skiprows=61)\n",
    "df = df.ix[1:11,'INDEX NAME':'2017 Q4']\n",
    "df = df.set_index('INDEX NAME').dropna(axis=1).ix[:,-21:]\n",
    "\n",
    "dfs = pd.DataFrame()  # Create new df for chart values\n",
    "dfs['mark'] = df.iloc[:,-1]\n",
    "dfs['avg'] = df.ix[:,-4:].mean(axis=1)\n",
    "dfs['max'] = df.max(axis=1)\n",
    "dfs['min'] = df.min(axis=1)\n",
    "dfs['neg'] = dfs.loc[dfs['min'] < 0]['min']\n",
    "dfs['min'] = dfs.loc[dfs['min'] >= 0]['min']\n",
    "dfs['max'] = dfs['max'].subtract(dfs['min'], fill_value=0)\n",
    "dfs.index.names = ['A']\n",
    "dfs = dfs.reset_index()\n",
    "\n",
    "dfs.replace({'S&P 500 ': ''}, regex=True, inplace=True)\n",
    "dfs.replace({'munication': ''}, regex=True, inplace=True)\n",
    "dfs.replace({'state.*$': 'state'}, regex=True, inplace=True)\n",
    "dfs = dfs.set_index('A').sort_values('mark', ascending=False)\n",
    "\n",
    "dfs.fillna('.').to_csv('eps.csv')  # csv file created\n",
    "\n",
    "write_txt('eps.txt', df.columns.values[-1]) # Latest quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Table of other indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:27.482891Z",
     "start_time": "2018-06-08T01:27:25.029653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series from the FRED pandas DataReader method\n",
    "fredseries = ['M2OWN', 'MORTGAGE30US', 'INDPRO', 'TWEXBMTH']\n",
    "start = datetime.datetime(2015,12,1)\n",
    "freddf = web.DataReader(fredseries, 'fred', start)\n",
    "\n",
    "# Volatility index (VIX) from CBOE\n",
    "vixurl = 'http://www.cboe.com/publish/scheduledtask/mktdata/datahouse/vixcurrent.csv'\n",
    "vixcol = ['Date', 'Open', 'High', 'Low', 'VIXCLS']\n",
    "vix = pd.read_csv(vixurl, skiprows=3000, names=vixcol, \n",
    "                  parse_dates=['Date']).set_index('Date')['VIXCLS']\n",
    "\n",
    "# Consumer confidence index data from the University of Michigan website\n",
    "cc_url = 'http://www.sca.isr.umich.edu/files/tbmics.csv'\n",
    "cc = pd.read_csv(cc_url, parse_dates={'DATE': ['Month', 'YYYY']})[-13:]\n",
    "cc = cc.set_index('DATE').rename(columns={'ICS_ALL':'cc'})['cc']\n",
    "\n",
    "# Yahoo Finance data on S&P index\n",
    "sp = pd.read_csv('C:/Working/USA/datafiles/stocks.csv', parse_dates = ['Date'])\n",
    "sp = sp.set_index('Date')['sp'].rename('Close').iloc[-350:]\n",
    "\n",
    "# Quandl data on oil and treasuries\n",
    "series = ['CHRIS/CME_CL1', 'USTREASURY/YIELD']\n",
    "subseries = ['USTREASURY/YIELD - 3 MO', 'USTREASURY/YIELD - 2 YR', \n",
    "             'USTREASURY/YIELD - 10 YR', 'CHRIS/CME_CL1 - Last']\n",
    "quandlsrs = quandl.get(series, start_date='2015-12-01')[subseries]\n",
    "quandlsrs.columns = ['3 MO', '2 YR', '10 YR', 'Last']\n",
    "\n",
    "df = pd.concat([quandlsrs, sp, vix, cc, freddf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:27.560999Z",
     "start_time": "2018-06-08T01:27:27.482891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary of table rows and guidance on their order, contents, and format\n",
    "d = {'3 MO':{'n':4,'name':'3-month treasury bill yield','m_ch':20,'y_ch':252, 't':'diff'},\n",
    "     '2 YR':{'n':5,'name':'2-year treasury bond yield','m_ch':20,'y_ch':252, 't':'diff'},\n",
    "     'INDPRO':{'n':10,'name':'Industrial production index','m_ch':1,'y_ch':12, 't':'pct'},\n",
    "     '10 YR':{'n':6,'name':'10-year treasury bond yield','m_ch':20,'y_ch':252, 't':'diff'},\n",
    "     'Last':{'n':9,'name':'Crude oil, US\\$/barrel','m_ch':20,'y_ch':252, 't':'pct'},\n",
    "     'M2OWN':{'n':3,'name':'Bank deposit interest rate','m_ch':1,'y_ch':12, 't':'diff'},\n",
    "     'cc':{'n':11,'name':'Consumer confidence index','m_ch':1,'y_ch':12, 't':'pct'},\n",
    "     'MORTGAGE30US':{'n':7,'name':'30-year mortgage rate','m_ch':4,'y_ch':52, 't':'diff'},             \n",
    "     'Close':{'n':1,'name':'S\\&P 500 index','m_ch':20,'y_ch':252, 't':'pct'},\n",
    "     'VIXCLS':{'n':2,'name':'CBOE volatility index (VIX)','m_ch':20,'y_ch':252, 't':'pct'},  \n",
    "     'TWEXBMTH':{'n':8,'name':'US Dollar, broad index','m_ch':1,'y_ch':12, 't':'pct'},\n",
    "    }\n",
    "# LaTeX arrows\n",
    "upar = '\\quad \\color{green!80!blue}$\\\\blacktriangle$\\\\normalcolor'\n",
    "dnar = '\\quad \\color{red!80!orange}$\\\\blacktriangledown$\\\\normalcolor'\n",
    "\n",
    "# This section adds a dictionary entry for the monthly and annual percent change columns\n",
    "# for each row in the table. Interest rate series get difference rather than pct_change.\n",
    "for k, v in d.items():\n",
    "    if d[k]['t'] == 'diff':\n",
    "        d[k]['val'] = '{:.2f}\\%'.format(round(df[k].dropna()[-1],2))\n",
    "    elif k in ['INDPRO','cc']:\n",
    "        d[k]['val'] = '{:.1f}'.format(round(df[k].dropna()[-1],1))\n",
    "    elif k in 'Last':\n",
    "        d[k]['val'] = '\\${:.2f}'.format(round(df[k].dropna()[-1],2))\n",
    "    else:\n",
    "        d[k]['val'] = '{:.2f}'.format(round(df[k].dropna()[-1],2))\n",
    "    if d[k]['m_ch'] == 1:\n",
    "        d[k]['date'] = df[k].dropna().index[-1].strftime('%b %Y')\n",
    "    else:\n",
    "        d[k]['date'] = df[k].dropna().index[-1].strftime('%Y-%m-%d')\n",
    "    for s in ['y', 'm']:  # Loop for yearly and monthly changes\n",
    "        # Define perecent change and difference:\n",
    "        pct_ch = df[k].dropna().pct_change(periods=d[k]['{}_ch'.format(s)])[-1]\n",
    "        diff_ch = df[k].dropna()[-1] - df[k].dropna()[-d[k]['{}_ch'.format(s)]-1]\n",
    "        if d[k]['t'] == 'pct':   \n",
    "            d[k]['{}_ch_v'.format(s)] = pct_ch*100\n",
    "            d[k]['{}_ch_s'.format(s)] = '{:.1f}\\%'.format(round(pct_ch*100,1))\n",
    "        else: \n",
    "            d[k]['{}_ch_v'.format(s)] = diff_ch\n",
    "            d[k]['{}_ch_s'.format(s)] = '{:.2f}$\\; $'.format(round(diff_ch,2))\n",
    "        if d[k]['{}_ch_v'.format(s)] > 0.005:\n",
    "            d[k]['{}_ar'.format(s)] = upar # Green up arrow if positive\n",
    "        elif d[k]['{}_ch_v'.format(s)] < -0.005:\n",
    "            d[k]['{}_ar'.format(s)] = dnar # Red down arrow if negative\n",
    "        else:\n",
    "            d[k]['{}_ar'.format(s)] = '' # For cases with no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:27.576615Z",
     "start_time": "2018-06-08T01:27:27.560999Z"
    }
   },
   "outputs": [],
   "source": [
    "order = {d[k]['n']: k for k in d.keys()}    \n",
    "# Write label to txt file\n",
    "\n",
    "with open('table1.txt', 'w') as text_file:\n",
    "    for n in range(1,12):\n",
    "        sd = d[order[n]]\n",
    "        text_file.write( ' \\ {} $\\quad$ & {} & {} & {} & {} & {} $\\; $& {} \\ \\\\\\ '.format(\n",
    "            sd['name'], sd['val'], sd['m_ar'], sd['m_ch_s'], \n",
    "            sd['y_ar'], sd['y_ch_s'], sd['date'])\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T01:27:33.623982Z",
     "start_time": "2018-06-08T01:27:27.576615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Working/bdecon.github.io/Dash/ExecDash.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LaTeX results\n",
    "os.chdir('C:/Working/Python/Macro_Dash/')\n",
    "os.system('pdflatex ExecDash.tex')\n",
    "shutil.copy('ExecDash.pdf', 'C:/Working/bdecon.github.io/Dash/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
