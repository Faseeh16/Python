{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python and LaTeX to create beautiful charts\n",
    "Brian W. Dew (brianwdew@gmail.com), as of January 15, 2017\n",
    "\n",
    "---\n",
    "\n",
    "#### Objective:\n",
    "Using python, obtain economic data from the web and save it as csv and txt files to be read by a LaTex file containing chart formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "if not os.path.exists('data/.'):\n",
    "    os.makedirs('data/.')\n",
    "\n",
    "os.chdir('data/.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chart 1 Real GDP growth by components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Updated inputs to pandas datareader:\n",
    "source = 'fred' \n",
    "start = datetime.datetime(2005,1,1)\n",
    "series = {'GDPC1': 'Total',\n",
    "          'GCEC1': 'Gov Spend',\n",
    "          'GPDIC1': 'Investment', \n",
    "          'NETEXC': 'Net Exports', \n",
    "          'PCECC96': 'Consumption'}\n",
    "\n",
    "# Retrieve data as pandas dataframe named df\n",
    "df = web.DataReader(series.keys(), source, start, )\n",
    "\n",
    "# Record GDP total\n",
    "df['Y'] = df['GDPC1']\n",
    "\n",
    "# Convert to share of total change\n",
    "for s in series.keys():\n",
    "    df[s] = (df[s] - df[s].shift(1))/df['Y'].shift(1) * 400\n",
    "\n",
    "Y = (df['Y'][-1] / 1000).round(decimals=1)\n",
    "df = df[series.keys()][4:].round(decimals=1)\n",
    "df.to_csv('gdp_comp.csv', header = True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "ch = df['GDPC1'][-1]\n",
    "\n",
    "# Write label to txt file\n",
    "with open('gdp_comp.txt', 'w') as text_file:\n",
    "    text_file.write(                  # txt file created\n",
    "        '{} Q{}: Real GDP: {}T; Growth: {}\\%'.format(y, q, Y, ch)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chart 2: Unemployment Rates\n",
    "\n",
    "Collect U3 data from FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime(2006,1,1) \n",
    "series = {'UNRATE': 'Total',\n",
    "          'LNS14027659': 'No diploma',\n",
    "          'LNS14027662': 'Adv. Degree'}\n",
    "\n",
    "# Retrieve data as pandas dataframe named df\n",
    "df = web.DataReader(series.keys(), source, start, )\n",
    "df.to_csv('unemp.csv', header = True)  # csv file created\n",
    "\n",
    "d1 = df.index[-1].strftime('%b %Y')\n",
    "\n",
    "# Write label to txt file\n",
    "with open('unemp.txt', 'w') as text_file:\n",
    "    text_file.write(                  # txt file created\n",
    "        '{}: {}\\% unemployed and looking for work'.format(d1, df['UNRATE'][-1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chart 3: U.S. Consumer Price Index since 2006\n",
    "\n",
    "The first chart is a line plot of the all-item consumer price index (FRED series: CPIAUCSL) and the \"core\" conumer price index (FRED series: CPILFESL) for all-urban consumers in the United States. The core CPI excludes food and energy prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inputs to the pandas datareader:\n",
    "start = datetime.datetime(2005,1,1) \n",
    "s1 = 'CPIAUCSL'            \n",
    "s2 = 'CPILFESL'             \n",
    "\n",
    "# Retrieve data as pandas dataframe named df\n",
    "df = web.DataReader([s1, s2], source, start, )\n",
    "\n",
    "# Obtain the annual percent change (inflation rate)\n",
    "for s in s1, s2:\n",
    "    df[s] = df[s].pct_change(periods=12) * 100\n",
    "    \n",
    "# Remove data not used in chart, round, and save as csv\n",
    "df = df[12:].round(decimals=1)\n",
    "df.to_csv('cpi.csv', header = True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "v1 = df[s1].iloc[-1]\n",
    "v2 = df[s2].iloc[-1]\n",
    "d1 = df.index[-1].strftime('%b %Y')\n",
    "\n",
    "# Write label to txt file\n",
    "with open('cpi.txt', 'w') as text_file:\n",
    "    text_file.write(                  # txt file created\n",
    "        '{}: All-items CPI: {}\\%; Core CPI: {}\\%'\n",
    "        .format(d1, v1, v2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chart 4: U.S. Consumer Price Index recent changes by category\n",
    "\n",
    "Second is a bar chart showing the most recent two month's changes in consumer prices for major categories of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Updated inputs to pandas datareader:\n",
    "start = datetime.datetime(2006,10,1)\n",
    "series = {'CPIOGSSL': 'Other goods \\& serv',\n",
    "          'CPIEDUSL': 'Education',\n",
    "          'CPIRECSL': 'Recreation', \n",
    "          'CPIFABSL': 'Food \\& Beverage', \n",
    "          'CPITRNSL': 'Transportation',\n",
    "          'CPIHOSSL': 'Housing', \n",
    "          'CPIENGSL': 'Energy', \n",
    "          'CPIMEDSL': 'Healthcare', \n",
    "          'CPIAPPSL': 'Apparel'}\n",
    "\n",
    "# Retrieve data as pandas dataframe named df\n",
    "df = web.DataReader(series.keys(), source, start, )\n",
    "df.columns = series.values()\n",
    "\n",
    "# Obtain the annual percent change (inflation rate)\n",
    "for s in df.keys():\n",
    "    df[s] = df[s].pct_change(periods=12) * 100\n",
    "d = {s: df[s][-120:].mean() for s in df.keys()} # Five year average\n",
    "\n",
    "# Write legend months to txt file\n",
    "with open('cpi_mo1.txt', 'w') as text_file:\n",
    "    text_file.write(df.index[-2].strftime('%b %Y'))\n",
    "with open('cpi_mo2.txt', 'w') as text_file:\n",
    "    text_file.write(df.index[-1].strftime('%b %Y'))  \n",
    "\n",
    "# Keep only latest two months, transpose, and round\n",
    "df = df.tail(2).transpose().round(decimals=1)\n",
    "df.columns = ['one', 'two']\n",
    "df.loc[:]['ten'] = [round(d[x],1) for x in df.index]\n",
    "df.index.name = 'Item'\n",
    "df = df.sort_values(by='two', axis=0, ascending=False)\n",
    "df.to_csv('cpi_comp.csv', header = True)  # csv file created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Chart 5: Earnings Per Share\n",
    "\n",
    "This chart reads data from Standard and Poors on the reported EPS of S&P 500 companies by sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get xlsx data from Standard and Poor's website\n",
    "spfile = 'https://us.spindices.com/documents/additional-material/sp-500-eps-est.xlsx'\n",
    "    \n",
    "df = pd.read_excel(spfile,sheetname='SECTOR EPS', skiprows=61)\n",
    "df = df.ix[1:11,'INDEX NAME':'2017 Q4']\n",
    "df = df.set_index('INDEX NAME').dropna(axis=1).ix[:,-21:]\n",
    "\n",
    "dfs = pd.DataFrame()\n",
    "dfs['mark'] = df.iloc[:,-1]\n",
    "dfs['avg'] = df.ix[:,-4:].mean(axis=1)\n",
    "dfs['max'] = df.max(axis=1)\n",
    "dfs['min'] = df.min(axis=1)\n",
    "dfs['neg'] = dfs.loc[dfs['min'] < 0]['min']\n",
    "dfs['min'] = dfs.loc[dfs['min'] >= 0]['min']\n",
    "dfs['max'] = dfs['max'].subtract(dfs['min'], fill_value=0)\n",
    "dfs.index.names = ['A']\n",
    "dfs = dfs.reset_index()\n",
    "\n",
    "dfs.replace({'S&P 500 ': ''}, regex=True, inplace=True)\n",
    "dfs.replace({'munication': ''}, regex=True, inplace=True)\n",
    "dfs.replace({'state.*$': 'state'}, regex=True, inplace=True)\n",
    "dfs = dfs.set_index('A').sort_values('mark', ascending=False)\n",
    "\n",
    "dfs.fillna('.').to_csv('eps.csv', header = True)  # csv file created\n",
    "\n",
    "eps_date = df.columns.values[-1]\n",
    "# Write label to txt file\n",
    "with open(\"eps.txt\", \"w\") as text_file:\n",
    "    text_file.write(                  # txt file created\n",
    "        '{}'.format(eps_date)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 1: Other Economic Indicators\n",
    "\n",
    "The final cell contains a table with recent developments for 11 other indicators. The data comes from three separate sources and has formatting specific to each indicator, therefore the code is quite lengthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Series to call from the Federal Reserve Economic Data (FRED) pandas DataReader method\n",
    "fredseries = ['M2OWN', 'MORTGAGE30US', 'INDPRO', 'TWEXBMTH']\n",
    "start = datetime.datetime(2015,10,1)\n",
    "freddf = web.DataReader(fredseries, source, start, ).reset_index()\n",
    "freddf['DATE'] = freddf['DATE'].dt.date\n",
    "freddf = freddf.set_index('DATE')\n",
    "\n",
    "# Volatility index (VIX) from CBOE\n",
    "vixurl = 'http://www.cboe.com/publish/scheduledtask/mktdata/datahouse/vixcurrent.csv'\n",
    "vixcol = ['Date', 'Open', 'High', 'Low', 'VIXCLS']\n",
    "vix = pd.read_csv(vixurl, skiprows=3000, names=vixcol, parse_dates=['Date']).set_index('Date')['VIXCLS']\n",
    "\n",
    "# Consumer confidence index data from the University of Michigan website\n",
    "cc_csv = 'http://www.sca.isr.umich.edu/files/tbmics.csv'\n",
    "df = pd.read_csv(cc_csv,parse_dates={'DATE': ['Month', 'YYYY']})[-13:]\n",
    "df['DATE'] = df['DATE'].dt.date\n",
    "cc = df.set_index('DATE').rename(columns={'ICS_ALL':'cc'})['cc']\n",
    "\n",
    "# Quandl requests\n",
    "quandlapi = 'https://www.quandl.com/api/v3/datasets/'\n",
    "quandlkey = '?api_key=x7q1kgMKv96cXx83GtSN'\n",
    "quandldts = '&start_date=2015-10-01'\n",
    "quandlsrs = {'wti':'CHRIS/CME_CL1.csv','treas':'USTREASURY/YIELD.csv','sp':'YAHOO/INDEX_GSPC.csv'}\n",
    "quandlurls = {k: '{}{}{}{}'.format(quandlapi, v, quandlkey, quandldts) for k,v in quandlsrs.iteritems()}\n",
    "d = {}\n",
    "for k,v in quandlurls.items():\n",
    "    d[k] = pd.read_csv(v, parse_dates=['Date'], nrows=300).set_index('Date').iloc[::-1]\n",
    "quandl = pd.concat([d['sp']['Close'],d['wti']['Last'],d['treas'][['3 MO','2 YR','10 YR']]],axis=1)\n",
    "quandl.index = pd.to_datetime(quandl.index)\n",
    "\n",
    "# DataFrame with all series in the Table\n",
    "df = pd.concat([quandl, vix, cc, freddf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of table rows and guidance on their order, contents, and format\n",
    "d = {'3 MO':{'n':4,'name':'3-month treasury bill yield','m_ch':20,'y_ch':252, 't':'diff'},\n",
    "     '2 YR':{'n':5,'name':'2-year treasury bond yield','m_ch':20,'y_ch':252, 't':'diff'},\n",
    "     'INDPRO':{'n':10,'name':'Industrial production index','m_ch':1,'y_ch':12, 't':'pct'},\n",
    "     '10 YR':{'n':6,'name':'10-year treasury bond yield','m_ch':20,'y_ch':252, 't':'diff'},\n",
    "     'Last':{'n':9,'name':'Crude oil, US\\$/barrel','m_ch':20,'y_ch':252, 't':'pct'},\n",
    "     'M2OWN':{'n':3,'name':'Bank deposit interest rate','m_ch':1,'y_ch':12, 't':'diff'},\n",
    "     'cc':{'n':11,'name':'Consumer confidence index','m_ch':1,'y_ch':12, 't':'pct'},\n",
    "     'MORTGAGE30US':{'n':7,'name':'30-year mortgage rate','m_ch':4,'y_ch':52, 't':'diff'},             \n",
    "     'Close':{'n':1,'name':'S\\&P 500 index','m_ch':20,'y_ch':252, 't':'pct'},\n",
    "     'VIXCLS':{'n':2,'name':'CBOE volatility index (VIX)','m_ch':20,'y_ch':252, 't':'pct'},  \n",
    "     'TWEXBMTH':{'n':8,'name':'US Dollar, broad index','m_ch':1,'y_ch':12, 't':'pct'},\n",
    "    }\n",
    "# LaTeX arrows\n",
    "upar = '\\quad \\color{green!80!blue}$\\\\blacktriangle$\\\\normalcolor'\n",
    "dnar = '\\quad \\color{red!80!orange}$\\\\blacktriangledown$\\\\normalcolor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This section adds a dictionary entry for the monthly and annual percent change columns\n",
    "# for each row in the table. Interest rate series get difference rather than pct_change.\n",
    "for k, v in d.iteritems():\n",
    "    if d[k]['t'] == 'diff':\n",
    "        d[k]['val'] = '{:.2f}\\%'.format(round(df[k].dropna()[-1],2))\n",
    "    elif k in ['INDPRO','cc']:\n",
    "        d[k]['val'] = '{:.1f}'.format(round(df[k].dropna()[-1],1))\n",
    "    elif k in 'Last':\n",
    "        d[k]['val'] = '\\${:.2f}'.format(round(df[k].dropna()[-1],2))\n",
    "    else:\n",
    "        d[k]['val'] = '{:.2f}'.format(round(df[k].dropna()[-1],2))\n",
    "    if d[k]['m_ch'] == 1:\n",
    "        d[k]['date'] = df[k].dropna().index[-1].strftime('%b %Y')\n",
    "    else:\n",
    "        d[k]['date'] = df[k].dropna().index[-1].strftime('%Y-%m-%d')\n",
    "    for s in ['y', 'm']:  # Loop for yearly and monthly changes\n",
    "        # Define perecent change and difference:\n",
    "        pct_ch = df[k].dropna().pct_change(periods=d[k]['{}_ch'.format(s)])[-1]\n",
    "        diff_ch = df[k].dropna()[-1] - df[k].dropna()[-d[k]['{}_ch'.format(s)]]\n",
    "        if d[k]['t'] == 'pct':   \n",
    "            d[k]['{}_ch_v'.format(s)] = pct_ch*100\n",
    "            d[k]['{}_ch_s'.format(s)] = '{:.1f}\\%'.format(round(pct_ch*100,1))\n",
    "        else: \n",
    "            d[k]['{}_ch_v'.format(s)] = diff_ch\n",
    "            d[k]['{}_ch_s'.format(s)] = '{:.2f}$\\; $'.format(round(diff_ch,2))\n",
    "        if d[k]['{}_ch_v'.format(s)] > 0.005:\n",
    "            d[k]['{}_ar'.format(s)] = upar # Green up arrow if positive\n",
    "        elif d[k]['{}_ch_v'.format(s)] < -0.005:\n",
    "            d[k]['{}_ar'.format(s)] = dnar # Red down arrow if negative\n",
    "        else:\n",
    "            d[k]['{}_ar'.format(s)] = '' # For cases with no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order = {d[k]['n']: k for k in d.keys()}    \n",
    "# Write label to txt file\n",
    "with open('table1.txt', 'w') as text_file:\n",
    "    for n in range(1,12):\n",
    "        sd = d[order[n]]\n",
    "        text_file.write( ' \\ {} $\\quad$ & {} & {} & {} & {} & {} $\\; $& {} \\ \\\\\\ '.format(\n",
    "            sd['name'], sd['val'], sd['m_ar'], sd['m_ch_s'], sd['y_ar'], sd['y_ch_s'], sd['date'])\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Run LaTeX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.system(\"pdflatex dash.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
