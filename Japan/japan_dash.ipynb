{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Japan Economic Dashboard\n",
    "\n",
    "Retrieve data on macroeconomic conditions in Japan and save as csv and txt files to be read by a .tex dashboard.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def write_txt(filename, filetext):\n",
    "# Write label to txt file\n",
    "    with open(filename, 'w') as text_file:\n",
    "        text_file.write(filetext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CPI data from e-stat.go.jp\n",
    "#http://www.e-stat.go.jp/SG1/estat/CsvdlE.do?sinfid=000031431696\n",
    "cpi_url = 'http://www.e-stat.go.jp/SG1/estat/CsvdlE.do?sinfid=000031431696'\n",
    "cpi_comp = {\n",
    "    'All items': 'All',\n",
    "    'All items, less food (less alcoholic beverages) and energy': 'Core',\n",
    "    'Food': 'Food \\& beverage',\n",
    "    'Housing': 'Housing',\n",
    "    'Furniture & household utensils': 'Furniture \\& utensils',\n",
    "    'Clothes & footwear': 'Apparel',\n",
    "    'Medical care': 'Healthcare',\n",
    "    'Transportation & communication': 'Transportation',\n",
    "    'Education': 'Education',\n",
    "    'Culture & recreation': 'Recreation',\n",
    "    'Energy': 'Energy'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(cpi_url, header=1).loc[424:].set_index('Group/Item')\n",
    "df = df[cpi_comp.keys()].pct_change(12).dropna()\n",
    "df['date'] = pd.to_datetime(df.index, format='%Y%m')\n",
    "df = df.reset_index().set_index('date').drop('Group/Item', 1).multiply(100).round(1)\n",
    "df.columns = df.columns.to_series().map(cpi_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['All', 'Core']].to_csv('data/cpi.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "v1 = df['All'].iloc[-1]\n",
    "v2 = df['Core'].iloc[-1]\n",
    "d1 = df.index[-1].strftime('%b %Y')\n",
    "text = '{}: All-items CPI: {}\\%; Core CPI: {}\\%'.format(d1, v1, v2)\n",
    "# Write label to txt file\n",
    "write_txt('data/cpi.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write legend months to txt file\n",
    "with open('data/cpi_mo1.txt', 'w') as text_file:\n",
    "    text_file.write(df.index[-2].strftime('%b %Y'))\n",
    "with open('data/cpi_mo2.txt', 'w') as text_file:\n",
    "    text_file.write(df.index[-1].strftime('%b %Y'))  \n",
    "\n",
    "d = {s: df[s][-120:].mean() for s in df.keys()} # Five year average\n",
    "    \n",
    "df = df.drop('Core', 1).tail(2).transpose().round(decimals=1)\n",
    "df.columns = ['one', 'two']\n",
    "df.index.name = 'Item'\n",
    "df['ten'] = df.index.to_series().map(d).round(1)\n",
    "df = df.set_index(df.reset_index()['Item'].replace('All', '\\\\textbf{All-items}'))\n",
    "df = df.sort_values(by='two', axis=0, ascending=False)\n",
    "df.to_csv('data/cpi_comp.csv', header = True)  # csv file created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP Growth by Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GDP\n",
    "r = requests.get('http://www.esri.cao.go.jp/en/sna/sokuhou/sokuhou_top.html')\n",
    "sub = r.content[r.text.find('Time series table') - 49:r.text.find('Time series table') - 2]\n",
    "base = 'http://www.esri.cao.go.jp/en/sna'\n",
    "base2 = 'http://www.esri.cao.go.jp/jp/sna'\n",
    "r2 = requests.get(base + sub.replace('..', ''))\n",
    "rloc = r2.text.find('Real, Seasonally Adjusted Series (Quarter-to-Quarter, Annualized)')\n",
    "sub2 = r2.content[rloc - 110:rloc - 18]\n",
    "url = '{}{}'.format(base2, sub2.replace('na/', '/'))\n",
    "url2 = url.replace('nritu','nkiyo')\n",
    "url3 = url.replace('nritu-j', 'gaku-m')\n",
    "url4 = url.replace('nritu', 'gaku')\n",
    "url5 = url.replace('nritu', 'kgaku')\n",
    "df = pd.read_csv(url2, header=5).loc[49:]\n",
    "gdpkeep = {\n",
    "    'Unnamed: 0': 'date',\n",
    "    'GDP(Expenditure Approach)': 'gdp',\n",
    "    'PrivateConsumption': 'cons',\n",
    "    'PrivateResidentialInvestment': 'inv1',\n",
    "    'Private Non-Resi.Investment': 'inv2',\n",
    "    'Changein PrivateInventories': 'inv3',\n",
    "    'GovernmentConsumption': 'gov1',\n",
    "    'PublicInvestment': 'gov2',\n",
    "    'Changein PublicInventories': 'gov3',\n",
    "    'Goods & Services': 'nx'\n",
    "}\n",
    "df = df[gdpkeep.keys()].dropna()\n",
    "df.columns = df.columns.to_series().map(gdpkeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dts = df['date'].str.split('-').str[0].str.split('/ ')\n",
    "for dt in dts:\n",
    "    if len(dt) == 1:\n",
    "        dt.append(dt[0])\n",
    "        dt[0] = None\n",
    "df['year'] = dts.str[0].fillna(method='ffill')\n",
    "df['month'] = dts.str[1].str.zfill(2)\n",
    "df['date2'] = df['year'].str.cat(df['month'], sep='-')\n",
    "df['date'] = pd.to_datetime(df['date2'], format='%Y-%m')\n",
    "df['inv'] = df['inv1'] + df['inv2'] + df['inv3']\n",
    "df['gov'] = df['gov1'] + df['gov2'] + df['gov3']\n",
    "df = df.set_index('date')[['gdp', 'cons', 'inv', 'gov', 'nx']]\n",
    "df.to_csv('data/gdp.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "Y = pd.read_csv(url4, header=5).iloc[49:, 1:2].dropna().iloc[-1].values[0]\n",
    "ch = df['gdp'][-1]\n",
    "text = '{} Q{}: Real GDP: {}billion Yen; Growth: {}\\%'.format(y, q, Y, ch)\n",
    "# Write label to txt file\n",
    "write_txt('data/gdp.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unemployment and participation\n",
    "unemp = 'http://www.stat.go.jp/data/roudou/longtime/zuhyou/lt01-a10.xls'\n",
    "\n",
    "df = pd.read_excel(unemp, skiprows=5, skip_footer=3).drop([1, 3])\n",
    "col1 = df.loc[0].fillna(method='ffill')\n",
    "col2 = df.loc[2]\n",
    "col = col1 + '-' + col2\n",
    "col[0] = 'year'\n",
    "col[1] = 'mon'\n",
    "col[2] = 'monname'\n",
    "col[3] = 'DEL'\n",
    "df = df.drop([0,2])\n",
    "df.columns = col.values\n",
    "df = df.drop('DEL', 1)\n",
    "df['month'] = df['mon'].str[:-1].str.zfill(2)\n",
    "df['year'] = df['year'].apply(pd.to_numeric, errors='coerce').shift(-1).fillna(method='ffill').astype(int)\n",
    "df['date2'] = df['year'].astype(str).str.cat(df['month'], sep='-')\n",
    "df['date'] = pd.to_datetime(df['date2'], format='%Y-%m')\n",
    "df = df.set_index('date').dropna()\n",
    "df['pop'] = df['Labour force-Both sexes'] + df['Not in labour force-Both sexes']\n",
    "df['partc'] = df['Labour force-Both sexes'] / df['pop'] * 100\n",
    "df['pop-m'] = df['Labour force-Male'] + df['Not in labour force-Male']\n",
    "df['partc-m'] = df['Labour force-Male'] / df['pop-m'] * 100\n",
    "df['pop-w'] = df['Labour force-Female'] + df['Not in labour force-Female']\n",
    "df['partc-w'] = df['Labour force-Female'] / df['pop-w'] * 100\n",
    "unemplt = df['Unemployment rate  (percent)-Both sexes'][-1]\n",
    "df['unemp'] = df['Unemployment rate  (percent)-Both sexes']\n",
    "d1 = df.index[-1].strftime('%b %Y')\n",
    "df = df[['partc', 'partc-m', 'partc-w', 'unemp']][636:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/labor.csv', header=True)  # csv file created\n",
    "text = 'Unemployment rate, both sexes: {}: {}\\%'.format(d1, unemplt)\n",
    "# Write label to txt file\n",
    "write_txt('data/labor.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nikkei 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BDew\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skip_footer; you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "# Nikkei 225\n",
    "df = pd.DataFrame()\n",
    "nikurl = 'http://indexes.nikkei.co.jp/en/nkave/historical/nikkei_stock_average_daily_en.csv'\n",
    "df['close'] = pd.read_csv(nikurl, skip_footer=1, parse_dates=['Date of Data']).set_index('Date of Data')['Close']\n",
    "df['vol'] = df['close'].pct_change() * 100\n",
    "df.index.name = 'date'\n",
    "d1 = df.index[-1].strftime('%b %#d, %Y')\n",
    "n1 = '{0:,.1f}'.format(df['close'][-1])\n",
    "\n",
    "# LaTeX arrows\n",
    "upar = ' \\color{green!80!blue}$\\\\blacktriangle$\\\\normalcolor'\n",
    "dnar = ' \\color{red!80!orange}$\\\\blacktriangledown$\\\\normalcolor'\n",
    "\n",
    "d = {}\n",
    "d['onemo'] = df['close'].dropna().pct_change(periods=21).multiply(100).round(1)[-1]\n",
    "d['oneyr'] = df['close'].dropna().pct_change(periods=252).multiply(100).round(1)[-1]\n",
    "for s in ['onemo', 'oneyr']:  # Loop for yearly and monthly changes\n",
    "    if d[s] > 0.005:\n",
    "        d[s+'_ar'] = upar # Green up arrow if positive\n",
    "    elif d[s] < -0.005:\n",
    "        d[s+'_ar'] = dnar # Red down arrow if negative\n",
    "    else:\n",
    "        d[s+'_ar'] = '' # For cases with no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna().to_csv('data/nikkei.csv', header=True)  # csv file created\n",
    "text = 'One-month change:{} {}\\%; \\\\\\ One-year change:{} {}\\%'.format(\n",
    "            d['onemo_ar'], d['onemo'], d['oneyr_ar'], d['oneyr'])\n",
    "text2 = 'Latest value: {}: {}'.format(d1, n1)\n",
    "# Write label to txt file\n",
    "write_txt('data/nikkei.txt', text)\n",
    "write_txt('data/nikkei2.txt', text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TANKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tankan Business Conditions\n",
    "series = {'COCOAEF1000601GCQ00000AT': 'All',\n",
    "     'COCOAEF1000601GCQ01000AT': 'Large',\n",
    "     'COCOAEF1000601GCQ02000AT': 'Medium',\n",
    "     'COCOAEF1000601GCQ03000AT': 'Small'\n",
    "     }\n",
    "d = {}\n",
    "df = pd.DataFrame()\n",
    "for k, v in series.items():\n",
    "    url = 'https://www.quandl.com/api/v3/datasets/BOJ/{}.csv?api_key=x7q1kgMKv96cXx83GtSN'.format(k)\n",
    "    d[v] = pd.read_csv(url, index_col='Date')\n",
    "df = pd.concat(d, axis=1, ignore_index=True)\n",
    "df.columns = ['All', 'Large', 'Medium', 'Small']\n",
    "df = df.dropna()[64:]\n",
    "df.index = pd.to_datetime(df.index)\n",
    "d1 = '{} Q{}'.format(df.index[-1].year, df.index[-1].quarter)\n",
    "all1 = df['All'][-1].astype(int)\n",
    "df.index.name = 'date'\n",
    "df.to_csv('data/tankan_bc.csv', header=True)  # csv file created\n",
    "text = 'As of {}: All-firms: {}'.format(d1, all1)\n",
    "# Write label to txt file\n",
    "write_txt('data/tankan_bc.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industrial Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Industrial production\n",
    "url = 'http://www.meti.go.jp/english/statistics/tyo/iip/xls/b2010_gsm1e.xls'\n",
    "series = {\n",
    "    2000000000: '\\\\textbf{All manufacturing and mining}',\n",
    "    '2AC0000000': 'Fabricated metals',\n",
    "    '2AD0000000': 'Machinery',\n",
    "    '2AE0000000': 'Electrical parts \\& devices',\n",
    "    '2AF0000000': 'Electrical machinery',\n",
    "    '2AG0000000': 'Information \\& communication eq.',\n",
    "    '2AH0000000': 'Transport equipment',\n",
    "    '2AJ0000000': 'Chemicals',\n",
    "    '2AL0000000': 'Plastic products',\n",
    "    '2AO0000000': 'Foods and tobacco',\n",
    "    '2AP0000000': 'Other manufacturing',\n",
    "}\n",
    "\n",
    "df = pd.read_excel(url, skiprows=2).set_index('Item_Number').ix[:,-60:]\n",
    "df = df[df.index.isin(series.keys())]\n",
    "df.replace({'-': None}, regex=True, inplace=True)\n",
    "dfs = pd.DataFrame()\n",
    "if len([col for col in df.columns if 'p' in str(col)]) > 0:\n",
    "    dfs['pre'] = df.iloc[:,-1]\n",
    "    dfs['lt'] = df.iloc[:,-2]\n",
    "    predate = '{} (Preliminary)'.format(pd.to_datetime(df.columns[-1][-6:], format='%Y%m').strftime('%b %Y'))\n",
    "    ltdate = '{}'.format(pd.to_datetime(df.columns[-2], format='%Y%m').strftime('%b %Y'))\n",
    "    legend = '\\legend{{\\scriptsize 5-year range, \\scriptsize 1-year average, \\scriptsize {}, \\scriptsize {}}}'.format(ltdate, predate)\n",
    "else:\n",
    "    dfs['pre'] = None\n",
    "    dfs['lt'] = df.iloc[:,-1]  \n",
    "    predate = None\n",
    "    ltdate = '{}'.format(pd.to_datetime(df.columns[-1], format='%Y%m').strftime('%b %Y'))\n",
    "    legend = '\\legend{{\\scriptsize 5-year range, \\scriptsize 1-year avg, \\scriptsize {}}}'.format(ltdate)\n",
    "dfs['avg'] = df.mean(axis=1) #.ix[:,-12:]\n",
    "dfs['min'] = df.min(axis=1)\n",
    "dfs['max'] = df.max(axis=1) - dfs['min']\n",
    "dfs['industry'] = dfs.index.to_series().map(series)\n",
    "dfs = dfs.sort_values('lt', ascending=False)\n",
    "dfs = dfs.reset_index()\n",
    "dfs = dfs.drop('Item_Number', 1).set_index('industry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_txt('data/ipleg.txt', legend)\n",
    "dfs.to_csv('data/ip.csv', header = True)  # csv file created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Current account from Ministry of Finance balance of payments data\n",
    "url = 'http://www.mof.go.jp/international_policy/reference/balance_of_payments/bp_trend/bpnet/sbp/s-a/6s-a-1.csv'\n",
    "columns = ['year' ,'quarter', 'cab', 'gs', 'goods', 'ex', 'im', 'serv', 'income', 'transfers']\n",
    "series = ['cab', 'goods', 'serv', 'income', 'transfers']\n",
    "df = pd.read_csv(url, skiprows=28, thousands=',').ix[:,2:].drop('Unnamed: 4',1)\n",
    "df.columns = columns\n",
    "df['quarter'] = df['quarter'].str[0]\n",
    "df['year'] = df['year'].fillna(method='ffill').astype(int)\n",
    "df['date'] = pd.to_datetime(df['year'].map(str) + 'Q' + df['quarter'])\n",
    "df = df.set_index('date')\n",
    "df = df.iloc[40:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nominal GDP from cabinet office\n",
    "ngdp = pd.read_csv(url3, header=5, thousands=',').iloc[49:, 0:2].dropna()\n",
    "dts = ngdp['Unnamed: 0'].str.split('-').str[0].str.split('/ ')\n",
    "for dt in dts:\n",
    "    if len(dt) == 1:\n",
    "        dt.append(dt[0])\n",
    "        dt[0] = None\n",
    "ngdp['year'] = dts.str[0].fillna(method='ffill')\n",
    "ngdp['month'] = dts.str[1].str.zfill(2)\n",
    "ngdp['date2'] = ngdp['year'].str.cat(ngdp['month'], sep='-')\n",
    "ngdp['date'] = pd.to_datetime(ngdp['date2'], format='%Y-%m')\n",
    "ngdp = ngdp.set_index('date')['GDP(Expenditure Approach)']\n",
    "ngdp.name = 'gdp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.join(ngdp).dropna()\n",
    "df = df[series].div(df['gdp'].multiply(.025), axis=0).round(2).join(df[['ex', 'im']].div(10))\n",
    "df.to_csv('data/external.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "lt = df['cab'][-1]\n",
    "exim = 'Exports: {:,}; Imports {:,}'.format(df['ex'][-1], df['im'][-1])\n",
    "text = '{} Q{}: Current Account Balance: {}\\% of GDP'.format(y, q, lt)\n",
    "text2 = '{} Q{}: {} (goods only, billion Yen)'.format(y, q, exim)\n",
    "# Write label to txt file\n",
    "write_txt('data/cab.txt', text)\n",
    "write_txt('data/tb.txt', text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url4, header=5, thousands=',').iloc[49:, [0,5,6,9]].dropna().set_index('Unnamed: 0')\n",
    "df['tot'] = df.sum(axis=1)\n",
    "\n",
    "series2 = {'PrivateResidentialInvestment': 'res',\n",
    "           'Private Non-Resi.Investment': 'bus', \n",
    "           'PublicInvestment': 'pub', \n",
    "           'tot': 'total'}\n",
    "\n",
    "df.columns = series2.values()\n",
    "# Convert to share of total change\n",
    "for k, v in series2.items():\n",
    "    df[v+'_ch'] = ((df[v] - df[v].shift(1))/df['total'].shift(1) * 400).round(2)\n",
    "    \n",
    "df['quarter'] = df.index.str.split('-').str[0].str.split('/ ').str[-1]\n",
    "df['year'] = [x for x in df.index.str.split('/ ').str[0].values if len(x) == 4 for n in range(4)][:len(df)]\n",
    "df['date'] = pd.to_datetime(df['year'].str.cat(df['quarter'], sep='-'))\n",
    "\n",
    "df = df.reset_index().set_index('date').drop(['quarter', 'year', 'Unnamed: 0'],1).dropna()\n",
    "df.to_csv('data/inv.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "I = df['total'][-1]\n",
    "ch = df['total_ch'][-1]\n",
    "text = 'Total investment expenditure: \\\\\\{} Q{}: {:,} billion Yen; Growth: {}\\%'.format(y, q, I, ch)\n",
    "# Write label to txt file\n",
    "write_txt('data/inv.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Household consumption expenditures\n",
    "df = pd.read_csv(url5, header=5, thousands=',').iloc[49:, [0,5,6,7,8]].dropna().set_index('Unnamed: 0')\n",
    "df['tot'] = df.sum(axis=1)\n",
    "\n",
    "series = {'DurableGoods': 'durable',\n",
    "           'Semi-DurableGoods': 'semidur', \n",
    "           'Non-DurableGoods': 'nondur', \n",
    "           'Services': 'services',\n",
    "          'tot': 'total'}\n",
    "\n",
    "df.columns = series.values()\n",
    "# Convert to share of total change\n",
    "for k, v in series.items():\n",
    "    df[v+'_ch'] = ((df[v] - df[v].shift(1))/df['total'].shift(1) * 400).round(2)\n",
    "\n",
    "df = df.dropna()    \n",
    "df['quarter'] = df.index.str.split('-').str[0].str.split('/ ').str[-1]\n",
    "df['year'] = [x for x in df.index.str.split('/ ').str[0].values if len(x) == 4 for n in range(4)][:len(df)]\n",
    "df['date'] = pd.to_datetime(df['year'].str.cat(df['quarter'], sep='-'))\n",
    "\n",
    "df = df.reset_index().set_index('date').drop(['quarter', 'year', 'Unnamed: 0'],1).dropna()\n",
    "df.to_csv('data/cons.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "C = df['total'][-1]\n",
    "ch = df['total_ch'][-1]\n",
    "text = 'Total household consumption expenditure: \\\\\\ {} Q{}: {:,} billion Yen; Growth: {}\\%'.format(y, q, C, ch)\n",
    "# Write label to txt file\n",
    "write_txt('data/cons.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### JGBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.mof.go.jp/english/jgbs/reference/interest_rate/jgbcme.csv'\n",
    "url1 = 'http://www.mof.go.jp/english/jgbs/reference/interest_rate/historical/jgbcme_all.csv'\n",
    "\n",
    "df = pd.read_csv(url, skiprows=1, parse_dates=['Date']).set_index('Date')\n",
    "df1 = pd.read_csv(url1, skiprows=1, parse_dates=['Date']).iloc[9700:].set_index('Date')\n",
    "\n",
    "df = df1.append(df)[['1Y', '2Y', '5Y', '10Y', '20Y', '30Y', '40Y']]\n",
    "\n",
    "prev1 = df.iloc[-246]\n",
    "prev1dt = '{}'.format(prev1.name.strftime('%b %#d, %Y'))\n",
    "prev5 = df.iloc[-1227]\n",
    "prev5dt = '{}'.format(prev5.name.strftime('%b %#d, %Y'))\n",
    "curr = df.iloc[-1]\n",
    "currdt = '{}'.format(curr.name.strftime('%b %#d, %Y'))\n",
    "head = [curr, prev1, prev5]\n",
    "df1 = pd.concat(head, 1)\n",
    "df1.columns = ['curr', 'prev1', 'prev5']\n",
    "df1['number'] = ['1', '2', '3', '4', '5', '6', '7']\n",
    "df1['alignment'] = 270\n",
    "df1.to_csv('data/jgb.csv', header=True)  # csv file created\n",
    "\n",
    "# Write label to txt file\n",
    "write_txt('data/jgb_prev1.txt', prev1dt)\n",
    "write_txt('data/jgb_prev5.txt', prev5dt)\n",
    "write_txt('data/jgb_curr.txt', currdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### USD-JPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.quandl.com/api/v3/datasets/CURRFX/JPYUSD.csv?api_key=x7q1kgMKv96cXx83GtSN&start_date=2014-01-01'\n",
    "url2 = 'https://www.quandl.com/api/v3/datasets/BOJ/STFX180110002.csv?api_key=x7q1kgMKv96cXx83GtSN&start_date=2014-01-01'\n",
    "url3 = 'https://www.quandl.com/api/v3/datasets/BOJ/STFX180110001.csv?api_key=x7q1kgMKv96cXx83GtSN&start_date=2014-01-01'\n",
    "df1 = pd.read_csv(url, parse_dates=['Date'], index_col='Date')['Rate']\n",
    "df2 = pd.read_csv(url2, parse_dates=['Date'], index_col='Date')\n",
    "df3 = pd.read_csv(url3, parse_dates=['Date'], index_col='Date')\n",
    "df = pd.concat([df1, df2, df3], 1)\n",
    "df.columns = ['Rate', 'REER', 'NEER']\n",
    "label = 'As of {}: {} JPY per 1 USD'.format(df.index[-1].strftime('%b %#d, %Y'), (1 / df['Rate'][-1]).round(2))\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].dropna() / df[column].dropna()[0]\n",
    "\n",
    "df.to_csv('data/fx.csv', header=True)  # csv file created\n",
    "\n",
    "# Write label to txt file\n",
    "write_txt('data/usdjpy.txt', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Government debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url4 = 'https://www.quandl.com/api/v3/datasets/BOJ/PFPFGD1.csv?api_key=x7q1kgMKv96cXx83GtSN&start_date=2006-01-01'\n",
    "url5 = 'https://www.quandl.com/api/v3/datasets/BOJ/PFPFGD220.csv?api_key=x7q1kgMKv96cXx83GtSN&start_date=2006-01-01'\n",
    "url6 = 'https://www.quandl.com/api/v3/datasets/BOJ/PFPFGD210.csv?api_key=x7q1kgMKv96cXx83GtSN&start_date=2006-01-01'\n",
    "df1 = pd.read_csv(url4, parse_dates=['Date'], index_col='Date')\n",
    "df2 = pd.read_csv(url5, parse_dates=['Date'], index_col='Date')\n",
    "df3 = pd.read_csv(url6, parse_dates=['Date'], index_col='Date')\n",
    "df = pd.concat([df1, df2, df3], 1)\n",
    "df.columns = ['Total', 'BOJ', 'Gov']\n",
    "df = df.iloc[::-1]\n",
    "df['BOJshare'] = df['BOJ'].div(df['Total']) * 100\n",
    "df['Govshare'] = df['Gov'].div(df['Total']) * 100\n",
    "df['Non-BOJ'] = df['Total'] - df['BOJ']\n",
    "label = 'BOJ share of total: {}: {}\\%'.format(df.index[-1].strftime('%b %d, %Y'), round(df['BOJshare'][-1],1))\n",
    "df.to_csv('data/gov_debt.csv', header=True)  # csv file created\n",
    "\n",
    "# Write label to txt file\n",
    "write_txt('data/gov_debt.txt', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
